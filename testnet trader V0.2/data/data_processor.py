# -*- coding: utf-8 -*-
# data/data_processor.py - FIXED VERSION

import pandas as pd
import numpy as np
from utils.indicators import calculate_indicators


def extract_advanced_features(df, cross_symbol_data=None, symbol=None):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ - ÙÙ‚Ø· Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡"""
    df = df.copy()

    try:
        current_symbol = symbol if symbol else getattr(df, "name", "UNKNOWN")

        # 1. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù‚ÛŒÙ…Øª (Ú©Ø§Ù‡Ø´ ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² overfitting)
        df["price_momentum_5"] = df["close"].pct_change(5)
        df["price_acceleration"] = df["close"].pct_change(5) - df["close"].pct_change(
            10
        )

        # 2. Ù†ÙˆØ³Ø§Ù†Ø§Øª ØªØ§Ø±ÛŒØ®ÛŒ (ÙÙ‚Ø· ÛŒÚ©ÛŒ)
        df["volatility_20"] = df["close"].rolling(20).std() / (
            df["close"].rolling(20).mean() + 1e-10
        )

        # 3. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø­Ø¬Ù… (Ú©Ø§Ù‡Ø´)
        df["volume_ratio"] = df["volume"] / (df["volume"].rolling(20).mean() + 1e-10)

        # 4. Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ÛŒ (ÙÙ‚Ø· body_size)
        df["body_size"] = (df["close"] - df["open"]).abs() / (
            df["high"] - df["low"] + 1e-10
        )

        # 5. Ù†Ø³Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…ØªÛŒ (Ú©Ø§Ù‡Ø´)
        df["price_to_sma20"] = df["close"] / (df["SMA_20"] + 1e-10)

        # 6. Ù‚Ø¯Ø±Øª Ø±ÙˆÙ†Ø¯
        df["trend_strength"] = (df["close"] - df["close"].rolling(20).mean()) / (
            df["close"].rolling(20).std() + 1e-10
        )

        # 7. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ³Ø§Ù†
        df["bb_position"] = (df["close"] - df["BB_Lower"]) / (
            df["BB_Upper"] - df["BB_Lower"] + 1e-10
        )

        # 8. Lagged features Ù…Ø­Ø¯ÙˆØ¯ (ÙÙ‚Ø· ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² overfitting)
        df["rsi_lag1"] = df["RSI"].shift(1)

        print(f"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ML Ø¨Ø±Ø§ÛŒ {current_symbol} Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ML Ø¨Ø±Ø§ÛŒ {current_symbol}: {e}")
        # Fallback Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡
        df["price_momentum_5"] = df["close"].pct_change(5)
        df["volatility_20"] = df["close"].rolling(20).std() / (
            df["close"].rolling(20).mean() + 1e-10
        )

    return df


def create_ml_features(df, target_lookahead=3):
    """Ø§ÛŒØ¬Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ ØªØ§Ø±Ú¯Øª - Ø¨Ø¯ÙˆÙ† Data Leakage"""
    from config import ML_SETTINGS

    target_lookahead = ML_SETTINGS["target_lookahead"]
    symbol = getattr(df, "name", "UNKNOWN")

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (ÙÙ‚Ø· Ø§Ø² Ú¯Ø°Ø´ØªÙ‡)
    df = extract_advanced_features(df, cross_symbol_data=None, symbol=symbol)

    # === Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ§Ø±Ú¯Øª (Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ØŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ training) ===
    # Ø§ÛŒÙ† Ø¨Ø®Ø´ ÙÙ‚Ø· Ù…ÙˆÙ‚Ø¹ training Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´Ù‡ØŒ Ù†Ù‡ prediction
    future_price = df["close"].shift(-target_lookahead)
    future_return = (future_price - df["close"]) / df["close"]

    # Ø¢Ø³ØªØ§Ù†Ù‡ Ù¾ÙˆÛŒØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ volatility
    market_volatility = df["close"].pct_change().std()
    return_threshold = max(0.02, market_volatility * 2)

    # ØªØ§Ø±Ú¯Øª Ø³Ù‡ Ú©Ù„Ø§Ø³ÛŒ
    target = pd.Series(0, index=df.index)
    target[future_return > return_threshold] = 1  # Ø®Ø±ÛŒØ¯
    target[future_return < -return_threshold] = -1  # ÙØ±ÙˆØ´

    # CRITICAL: target Ø±Ùˆ Ø¬Ø¯Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…ØŒ Ù†Ù‡ ØªÙˆÛŒ df
    df["target"] = target

    print(f"ðŸ“Œ Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ§Ø±Ú¯Øª {symbol}: Â±{return_threshold*100:.2f}%")

    # Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ (Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² overfitting)
    feature_columns = [
        # Momentum
        "price_momentum_5",
        "price_acceleration",
        # Volatility
        "volatility_20",
        # Volume
        "volume_ratio",
        # Candle patterns
        "body_size",
        # Technical indicators
        "RSI",
        "MACD",
        "ADX",
        # Price ratios
        "price_to_sma20",
        # Trend
        "trend_strength",
        # Bollinger
        "bb_position",
        # Lagged
        "rsi_lag1",
    ]

    # ÙÙ‚Ø· ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†
    available_features = [f for f in feature_columns if f in df.columns]

    # Ø­Ø°Ù NaN Ù‡Ø§
    required_cols = available_features + ["target"]
    df_clean = df[required_cols].dropna()

    print(f"ðŸ“Š ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {len(available_features)}")
    print(f"ðŸ“ˆ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(df_clean)}")

    # Ù†Ù…Ø§ÛŒØ´ ØªÙˆØ²ÛŒØ¹ ØªØ§Ø±Ú¯Øª
    target_dist = df_clean["target"].value_counts().sort_index()
    print(
        f"ðŸ“Š ØªÙˆØ²ÛŒØ¹: Sell={target_dist.get(-1, 0)}, Hold={target_dist.get(0, 0)}, Buy={target_dist.get(1, 0)}"
    )

    return df_clean, available_features


def prepare_train_test_split(df, feature_columns, test_size=0.3):
    """Split Ø¨Ø¯ÙˆÙ† Leakage Ø¨Ø±Ø§ÛŒ Time Series"""
    from sklearn.preprocessing import StandardScaler

    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
    df = df.sort_index()

    # Split Ù†Ù‚Ø·Ù‡
    split_idx = int(len(df) * (1 - test_size))

    # Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ
    train_df = df.iloc[:split_idx].copy()
    test_df = df.iloc[split_idx:].copy()

    # X Ùˆ y
    X_train = train_df[feature_columns]
    y_train = train_df["target"]
    X_test = test_df[feature_columns]
    y_test = test_df["target"]

    # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ (ÙÙ‚Ø· Ø±ÙˆÛŒ train fit Ù…ÛŒØ´Ù‡)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)  # ÙÙ‚Ø· transform

    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
    X_train_scaled = pd.DataFrame(
        X_train_scaled, columns=feature_columns, index=X_train.index
    )
    X_test_scaled = pd.DataFrame(
        X_test_scaled, columns=feature_columns, index=X_test.index
    )

    print(f"ðŸ“Š Train: {len(X_train)} ({train_df.index[0]} to {train_df.index[-1]})")
    print(f"ðŸ“Š Test: {len(X_test)} ({test_df.index[0]} to {test_df.index[-1]})")

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler


def walk_forward_validation(df, feature_columns, n_splits=5):
    """Walk-Forward Validation"""
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.preprocessing import StandardScaler

    df = df.sort_index()
    tscv = TimeSeriesSplit(n_splits=n_splits)

    X = df[feature_columns]
    y = df["target"]

    fold_results = []

    for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):
        # Split
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        # Scale (Ù‡Ø± fold Ø¬Ø¯Ø§)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
        X_train_scaled = pd.DataFrame(
            X_train_scaled, columns=feature_columns, index=X_train.index
        )
        X_test_scaled = pd.DataFrame(
            X_test_scaled, columns=feature_columns, index=X_test.index
        )

        print(f"ðŸ“Š Fold {fold}: Train={len(X_train)}, Test={len(X_test)}")

        fold_results.append(
            {
                "X_train": X_train_scaled,
                "X_test": X_test_scaled,
                "y_train": y_train,
                "y_test": y_test,
                "scaler": scaler,
            }
        )

    return fold_results
